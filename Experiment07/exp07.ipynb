{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------ RELATED -------------------------------\n",
      "Accuracy Score:\n",
      "0.554524361949\n",
      "roc score:\n",
      "0.520304651671\n",
      "[[440  42]\n",
      " [342  38]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.56      0.91      0.70       482\n",
      "        1.0       0.47      0.10      0.17       380\n",
      "\n",
      "avg / total       0.52      0.55      0.46       862\n",
      "\n",
      "[ 0.55555556  0.53310105  0.56097561  0.59233449  0.58188153  0.56097561\n",
      "  0.55052265  0.54006969  0.54006969  0.54703833]\n",
      "0.556252419667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n# ## (Self) Model Evaluation Using a Validation Set\\n\\n# In[82]:\\n\\nX_train3, X_test3, y_train3, y_test3 = train_test_split(X3, y3, test_size=0.3, random_state=0)\\nmodel_test3 = LogisticRegression()\\nmodel_test3.fit(X_train3, y_train3)\\n# predict class labels for the test set\\npredicted3 = model_test.predict(X_test3)\\n# generate class probabilities\\nprobs = model_test.predict_proba(X_test3)\\n# generate evaluation metrics\\nprint '------------------ RELATED -------------------------------'\\nprint 'Accuracy Score:'\\nprint metrics.accuracy_score(y_test3, predicted3)\\nprint 'roc score:'\\nprint metrics.roc_auc_score(y_test3, probs[:, 1])\\nprint metrics.confusion_matrix(y_test3, predicted3)\\nprint metrics.classification_report(y_test3, predicted3)\\n# Evaluate the model using 10-fold cross-validation\\nscores3 = cross_val_score(LogisticRegression(), X3, y3, scoring='accuracy', cv=10)\\nprint scores3\\nprint 'Mean Score:'\\nprint scores3.mean()\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from patsy import dmatrices\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "# Load dataset\n",
    "#related =  pd.read_csv(\"./data_vectorised/related.csv\")\n",
    "infection2 =  pd.read_csv(\"./infection2.csv\")\n",
    "#self =  pd.read_csv(\"./data_vectorised/self.csv\")\n",
    "\n",
    "\n",
    "# ## Data Exploration\n",
    "\n",
    "\n",
    "# ## Logistic Regression\n",
    "infection2.head()\n",
    "\n",
    "related_params = \"RESULT ~ flu + gett + shot + think + sick + get + worried + feel + go + h1n1 + lik + got + scared + hop + bett + worry + fear + vaccin + today + one + still + need + cold + really + hom\"\n",
    "infection_params = \"RESULT ~ sick + feel + got + lik + go + im + get + still + hom + good + cold + work + today + cough + bad + sore + nose + runny + manflu + flu\"\n",
    "self_params = \"RESULT ~ flu + gett + shot + think + sick + feel + get + got + go + lik + im + bett + hop + worried + today + still + day + scared + week + vaccin + good + cold + worry + work + back\"\n",
    "\n",
    "'''\n",
    "# ## Related\n",
    "y, X = dmatrices(related_params, related, return_type='dataframe')\n",
    "# flatten y into a 1-D array\n",
    "y = np.ravel(y)\n",
    "# instantiate a logistic regression model, and fit with X and y\n",
    "model = LogisticRegression()\n",
    "model = model.fit(X,y)\n",
    "# check the accuracy on the training set\n",
    "model.score(X, y)\n",
    "\n",
    "\n",
    "# ## Self\n",
    "y3, X3 = dmatrices(self_params, self, return_type='dataframe')\n",
    "# flatten y into a 1-D array\n",
    "y3 = np.ravel(y3)\n",
    "# instantiate a logistic regression model, and fit with X and y\n",
    "model3 = LogisticRegression()\n",
    "model3 = model3.fit(X3,y3)\n",
    "# check the accuracy on the training set\n",
    "model2.score(X3, y3)\n",
    "\n",
    "'''\n",
    "\n",
    "# ## Infection\n",
    "y2, X2 = dmatrices(infection_params, infection, return_type='dataframe')\n",
    "# flatten y into a 1-D array\n",
    "y2 = np.ravel(y2)\n",
    "# instantiate a logistic regression model, and fit with X and y\n",
    "model2 = LogisticRegression()\n",
    "model2 = model2.fit(X2,y2)\n",
    "# check the accuracy on the training set\n",
    "model2.score(X2, y2)\n",
    "'''\n",
    "# ## (Related)Model Evaluation Using a Validation Set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "model_test = LogisticRegression()\n",
    "model_test.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# We now need to predict class labels for the test set. We will also generate the class probabilities, just to take a look.\n",
    "# predict class labels for the test set\n",
    "predicted = model_test.predict(X_test)\n",
    "print predicted\n",
    "\n",
    "# generate class probabilities\n",
    "probs = model_test.predict_proba(X_test)\n",
    "print probs\n",
    "\n",
    "\n",
    "# As can be seen, the classifier is predicting a 1 any time the probability in the second column is greater than 0.5.\n",
    "# \n",
    "# Now let's generate some evaluation metrics.\n",
    "\n",
    "# In[69]:\n",
    "\n",
    "# generate evaluation metrics\n",
    "print '------------------ RELATED -------------------------------'\n",
    "print metrics.accuracy_score(y_test, predicted)\n",
    "print metrics.roc_auc_score(y_test, probs[:, 1])\n",
    "\n",
    "\n",
    "# The accuracy is 68%, which is the same as I experienced when training and predicting on the same data.\n",
    "# We can also see the confusion matrix and a classification report with other metrics\n",
    "\n",
    "# In[65]:\n",
    "\n",
    "print metrics.confusion_matrix(y_test, predicted)\n",
    "print metrics.classification_report(y_test, predicted)\n",
    "\n",
    "\n",
    "# ## Model Evaluation Using Cross-Validation\n",
    "\n",
    "# Now let's try 10-fold cross-validation, to see if the accuracy holds up more rigorously.\n",
    "\n",
    "# In[68]:\n",
    "\n",
    "# Evaluate the model using 10-fold cross-validation\n",
    "scores = cross_val_score(LogisticRegression(), X, y, scoring='accuracy', cv=10)\n",
    "print scores\n",
    "print scores.mean()\n",
    "\n",
    "\n",
    "# It's still performing at 68% accuracy'\n",
    "\n",
    "# ##Â Predicting the Probability that a tweet is related to influenza\n",
    "\n",
    "# In[70]:\n",
    "\n",
    "#X = np.array([1,3,0,1,0,0,0,0,0,1,1])\n",
    "#X.reshape(-1, 1)\n",
    "#model.predict_proba(X)\n",
    "'''\n",
    "\n",
    "# ## (Infection)Model Evaluation Using a Validation Set\n",
    "\n",
    "# In[78]:\n",
    "\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size=0.3, random_state=0)\n",
    "model_test2 = LogisticRegression()\n",
    "model_test2.fit(X_train2, y_train2)\n",
    "# predict class labels for the test set\n",
    "predicted2 = model_test2.predict(X_test2)\n",
    "# generate class probabilities\n",
    "probs = model_test2.predict_proba(X_test2)\n",
    "# generate evaluation metrics\n",
    "print '------------------ RELATED -------------------------------'\n",
    "print 'Accuracy Score:'\n",
    "print metrics.accuracy_score(y_test2, predicted2)\n",
    "print 'roc score:'\n",
    "print metrics.roc_auc_score(y_test2, probs[:, 1])\n",
    "print metrics.confusion_matrix(y_test2, predicted2)\n",
    "print metrics.classification_report(y_test2, predicted2)\n",
    "# Evaluate the model using 10-fold cross-validation\n",
    "scores2 = cross_val_score(LogisticRegression(), X2, y2, scoring='accuracy', cv=10)\n",
    "print scores2\n",
    "print scores2.mean()\n",
    "\n",
    "'''\n",
    "# ## (Self) Model Evaluation Using a Validation Set\n",
    "\n",
    "# In[82]:\n",
    "\n",
    "X_train3, X_test3, y_train3, y_test3 = train_test_split(X3, y3, test_size=0.3, random_state=0)\n",
    "model_test3 = LogisticRegression()\n",
    "model_test3.fit(X_train3, y_train3)\n",
    "# predict class labels for the test set\n",
    "predicted3 = model_test.predict(X_test3)\n",
    "# generate class probabilities\n",
    "probs = model_test.predict_proba(X_test3)\n",
    "# generate evaluation metrics\n",
    "print '------------------ RELATED -------------------------------'\n",
    "print 'Accuracy Score:'\n",
    "print metrics.accuracy_score(y_test3, predicted3)\n",
    "print 'roc score:'\n",
    "print metrics.roc_auc_score(y_test3, probs[:, 1])\n",
    "print metrics.confusion_matrix(y_test3, predicted3)\n",
    "print metrics.classification_report(y_test3, predicted3)\n",
    "# Evaluate the model using 10-fold cross-validation\n",
    "scores3 = cross_val_score(LogisticRegression(), X3, y3, scoring='accuracy', cv=10)\n",
    "print scores3\n",
    "print 'Mean Score:'\n",
    "print scores3.mean()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
